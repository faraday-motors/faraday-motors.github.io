<div class="container">
  <div class="row">
    <div class="col-lg-12 text-center">
      <h2 class="section-heading">Modeling</h2>
      <h3 class="section-subheading text-muted">Applying Machine Learning Techniques to Determine<br />Demographic Features Most Associated with EV Ownership</h3>
    </div>
  </div>
  <div class="row">
    <h3>Initial Feature Selection and Model Evaluation</h3>
    <br />
    <p>The urban areas data set contains aggregated EV charging stations for each of 3,600 urban areas and we used the raw station count as our dependent variable or label and turned the modeling exercise into a classic supervised learning problem. The predictors or independent variables are the demographic covariates from the Census American Community Survey data and EV incentives (at the state level). The diagram below illustrates our modeling methodology and approach.</p>
    <br />
    <div class="row text-center"><img src="../modelingmethodology/modeling_methodology.png" alt="" width="750"></div>
    <br />
    <p>We took two parallel paths, a path for finding the best algorithm for the problem with an initial feature set and another path for systematic feature search and optimization, to arrive at our optimal model. We selected an initial subset of the features from the original set of 73 demographic covariates (features), based on our ‘gut’ feel and some recent EV surveys. The initial features selected include number of high-income households, education levels (e.g., % of college graduates), home ownership, and the populations of different age groups.</p>
    <p>Our initial models contained 10 and 25 features and we ran the following 4 different learners, two linear learners: linear regression and logistic regression, and two ensemble learners: Random Forest (L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001) and extremely randomized decision trees (P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006, ExtraTrees in sklearn with >200 trees). To evaluate the different learners, we first examined the various scores derived from the test data set (http://scikit-learn.org/stable/modules/model_evaluation.html), average accuracy scores and R^2 scores were most useful. We then visually examined the predicted charging station counts vs. the actual charing station counts. Since ROC curves are not relevant for multi-class classification and regression, we find our simple visualization extremely effective in identifying models that overfit.</p>
    <div class="row text-center"><img src="../modelingmethodology/table.png" alt="" width="500"></div>
    <br />
    <br />
    <p>It was no surprise that we discovered many regressors overfitted the training set. Our visual examination was critical for us to quickly assess different learners and choose the best algorithm for the problem. Overfitting was obvious visually: when the predicted vs actual station counts for training set all line up diagonally while the predicted vs. actual counts for the test set scatter or cluster above or below the diagonal line, we know that the algorithm overfitted the training set.</p>
    <p>We found that ensemble learners were more accurate than the linear learners by 14-27%. Overall, the Random Forest regressor had the second best scores (>85% for both accuracy and R^2 scores) and it also did not overfit the training set. Logistic Regression and extremely randomized trees grossly overfit the training set. By definition, Random Forest’s ‘bagging’ and random feature selection effectively avoids the issue of overfitting.
    </p>
    <div class="row text-center"><img src="../modelingmethodology/Fig-LinearRegression.png" alt="" width="500"><img src="../modelingmethodology/Fig-LogisticRegression.png" alt="" width="500"></div>
    <div class="row text-center"><img src="../modelingmethodology/Fig-RandomForest.png" alt="" width="500"><img src="../modelingmethodology/Fig-DecisionTrees.png" alt="" width="500"></div>
    <br />
    <br />
    <br />
    <br />
    <div class="row"></div>
    <div class="col-lg-4 "></div>
    <div class="col-lg-4 "></div>
  </div>
  <h3>Feature Selection and Minimal Optimal Model</h3>
  <p>Now that we determined a Random Forest regressor worked the best with ad-hoc features, we needed a systematic way to search the feature space as we did not want to just rely on gut feel or the existing surveys and research. Our goal is to discover demographic features and other covariates that are not obviously correlated with EV prevalence or interest. We found in the literature a novel feature selection algorithm proposed by Kursa and Rudnicki in 2010 (http://www.jstatsoft.org/v36/i11/paper). The proposed algorithm was designed as wrapper around a Random Forest learner and it iteratively eliminates features by using a statistical test (z-score). They implemented this as an R package, Boruta. Daniel Homola ported a Python implementation (https://bitbucket.org/danielhomola/boruta_py/) of Boruta and it works out of box with sklearn, the Python machine learning package we used. Running Boruta for all available features consistently returned a set of 9 or so features which provided us with valuable insights into our data set. It was encouraging and satisfying that many of the significant features returned by Boruta also coincide with our initial gut feel. Features such as the number of households with income over $100,000, the populations of young people in the 25 to 34 year old and the 35 to 44 year old age groups, and total number of college graduates, showed up consistently in Boruta outputs. Our ad-hoc feature selections included many of these features plus the overall population and number of households. Interestingly, the total population and number of households were never significant in either the ad-hoc modeling and the Boruta feature searching, indicating that the raw number of EV charging stations do not track population and other features are more significant for EV interest or prevalence. A result that we were hoping to get from the start!</p>
  <p>Combining the Boruta results and that from the ad-hoc modeling, we selected 14 features for our “minimal optimal” feature set to feed into a Random Forest classifier. Theoretically, Occam’s Razor or the principle of parsimony calls for models that contain all that is necessary but nothing more. Practically, a minimal optimal model is attractive for it provides the best explanation of the data and has the most predictive power but with the smallest set of relevant features. Our final model has excellent predictive power (with scores >85% for the test set) and is also not sensitive to the number of features as long as the most significant features such as, the households of the highest income brackets and the population of young age groups, are included. We used the output from our optimal model to predict the “best markets” for Faraday Motor’s marketing division.
  </p>
  <div class="row text-center"><img src="../modelingmethodology/Fig-RandomForest-Optimal.png" alt="" width="500"></div>
</div>
