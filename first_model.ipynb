{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import *\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read merged data file with charging stations and ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32517,) (32517, 3) [  6.40200000e+03   4.97188379e-01   0.00000000e+00] 1.0\n",
      "(32517, 3) (32517,) [  2.77250000e+04   4.84147881e-01   7.08960989e-01] 1.0\n",
      "float64 float64\n",
      "float64\n",
      "32517 24387\n",
      "(24387, 3) (24387,)\n",
      "(8130, 3) (8130,)\n",
      "[ 0.  0.  0.] 1.0\n",
      "[  1.64680000e+04   5.06922516e-01   6.86856451e-01] 0.0\n"
     ]
    }
   ],
   "source": [
    "#import the merged charging station and ACS data\n",
    "lines = open('data/add_0_stations.csv').read().splitlines()\n",
    "#Remove the first row, it's just the headings\n",
    "lines.pop(0)\n",
    "\n",
    "zip_code, count, population, male_pct, age, college_pct, income, home_pct = [], [], [], [], [], [], [], []\n",
    "for line in lines:\n",
    "    items = line.split(',')\n",
    "    zip_code.append(items[0])\n",
    "    count.append(float(items[1]))\n",
    "    population.append(float(items[2]))\n",
    "    male_pct.append(float(items[3]))\n",
    "    age.append(items[4])\n",
    "    college_pct.append(items[5])\n",
    "    income.append(items[6])\n",
    "    home_pct.append(float(items[7]))\n",
    "    \n",
    "# combine lists to numpy arrays for data and labels\n",
    "Y=np.array(count)\n",
    "# X=np.vstack((population,male_pct, age, college_pct, income, home_pct))\n",
    "X=np.vstack((population, male_pct, home_pct))\n",
    "X=np.transpose(X)\n",
    "print Y.shape, X.shape, X[0], Y[0]\n",
    "\n",
    "# add shuffle code before splitting the data into train and dev sets\n",
    "# easiest shuffle utility is sklearn shuffle function\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# shuffle two arrays in unison\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "print X.shape, Y.shape, X[0], Y[0]\n",
    "# determine the data type of the two arrays\n",
    "print X.dtype, Y.dtype\n",
    "# convert to strings\n",
    "# must handle missing values first by making missing values zeros\n",
    "X[X==''] = '0'\n",
    "# now convert to float or leave them alone - converting now to make the code cleaner\n",
    "X1=X.astype(np.float)\n",
    "print X1.dtype\n",
    "\n",
    "# Split the imported data into training 75% and development data 25%\n",
    "\n",
    "split = 3*len(zip_code)/4\n",
    "\n",
    "print len(zip_code), split\n",
    "\n",
    "train_data, train_labels = X[:split], Y[:split]\n",
    "dev_data, dev_labels = X[split:], Y[split:]\n",
    "\n",
    "print train_data.shape, train_labels.shape\n",
    "print dev_data.shape, dev_labels.shape\n",
    "print train_data[0], train_labels[0]\n",
    "print dev_data[0], dev_labels[0]\n",
    "# dev_dat=np.array(dev_data)\n",
    "# print dev_dat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([  2.53171301e-05,   1.84813537e-01,  -1.17812150e+00]))\n",
      "Variance score: 0.15\n"
     ]
    }
   ],
   "source": [
    "# try lineary regression mode\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(train_data, train_labels)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# score\n",
    "print('Variance score: %.2f' % regr.score(dev_data, dev_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863099630996\n"
     ]
    }
   ],
   "source": [
    "# fit the first model with logistic regression \n",
    "#\n",
    "logreg = LogisticRegression(penalty='l1', C=1.0, tol=0.01) \n",
    "logreg.fit(train_data, train_labels)\n",
    "print logreg.score(dev_data, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
